{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no shortage of tutorials on the web which show you how to recognize digits from images in the MNIST corpus using only 10 lines of python. It is certainly remarkable how low the barriers to entry are for constructing and training neural networks. But when you attempt to solve a real-world problem, you may find that these tutorials don't apply. You don't have enough data to do anything useful with neural networks. (Maybe you want to use a simpler regression or tree-based model, but that's a post for another day and another author.) Your data might be messy, a big pile of numeric and text features, unnormalized and unembedded. You need to do __feature engineering__, and you're in luck: `scikit-learn` has a number of utilities to make this easier.\n",
    "\n",
    "In post, we'll survey some techniques for pre-processing your data using `scikit-learn`. These techniques are broadly applicable, transforming input data into forms that are useful for various machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn import feature_extraction, preprocessing\n",
    "\n",
    "# the following is purely for the purposes of pretty printing matrices\n",
    "from IPython.display import display\n",
    "import sympy; sympy.init_printing()\n",
    "\n",
    "def display_matrix(m):\n",
    "    display(sympy.Matrix(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "\n",
    "Below, we have a number of opening sentences and phrases from famous novels. To use the parlance of [NLP](https://en.wikipedia.org/wiki/Natural_Language_Processing), each line below is a (short) _document_, and the collection of documents is a _corpus_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Call me Ishmael.\",\n",
    "    \"It is a truth universally acknowledged\",\n",
    "    \"A screaming comes across the sky.\",\n",
    "    \"Many years later, as he faced the firing\",\n",
    "    \"Happy families are all alike.\",\n",
    "    \"It was a bright cold day in April\",\n",
    "    \"I am an invisible man.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way to make this data more useful is to count the number of occurrences of each word in each document. To do this, we can use a a `CountVectorizer` from the `feature_extraction.text` package of `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "\n",
    "count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7x35 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 37 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = count_vectorizer.transform(corpus)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{array}{ccccccccccccccccccccccccccccccccccc}0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0\\\\0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1\\\\0 & 0 & 1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\\\0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\end{array}\\right]$$"
      ],
      "text/plain": [
       "⎡0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0 \n",
       "⎢                                                                             \n",
       "⎢1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0 \n",
       "⎢                                                                             \n",
       "⎢0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0 \n",
       "⎢                                                                             \n",
       "⎢0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  1  0  1  0  0  0  0  0  1  0 \n",
       "⎢                                                                             \n",
       "⎢0  0  1  1  0  0  0  1  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0 \n",
       "⎢                                                                             \n",
       "⎢0  0  0  0  0  0  1  0  0  1  0  1  0  1  0  0  0  0  0  1  0  0  0  1  0  0 \n",
       "⎢                                                                             \n",
       "⎣0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1 \n",
       "\n",
       " 0  1  0  0  0  0  0  0  0⎤\n",
       "                          ⎥\n",
       " 0  0  0  0  0  1  1  0  0⎥\n",
       "                          ⎥\n",
       " 0  0  1  1  1  0  0  0  0⎥\n",
       "                          ⎥\n",
       " 1  0  0  0  1  0  0  0  1⎥\n",
       "                          ⎥\n",
       " 0  0  0  0  0  0  0  0  0⎥\n",
       "                          ⎥\n",
       " 0  0  0  0  0  0  0  1  0⎥\n",
       "                          ⎥\n",
       " 0  0  0  0  0  0  0  0  0⎦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_matrix(result.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{array}{ccccccccccccccccccccccccccccccccccc}0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0\\\\0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1\\\\0 & 0 & 1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\\\0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\end{array}\\right]$$"
      ],
      "text/plain": [
       "⎡0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0 \n",
       "⎢                                                                             \n",
       "⎢1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0 \n",
       "⎢                                                                             \n",
       "⎢0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0 \n",
       "⎢                                                                             \n",
       "⎢0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  1  0  1  0  0  0  0  0  1  0 \n",
       "⎢                                                                             \n",
       "⎢0  0  1  1  0  0  0  1  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0 \n",
       "⎢                                                                             \n",
       "⎢0  0  0  0  0  0  1  0  0  1  0  1  0  1  0  0  0  0  0  1  0  0  0  1  0  0 \n",
       "⎢                                                                             \n",
       "⎣0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1 \n",
       "\n",
       " 0  1  0  0  0  0  0  0  0⎤\n",
       "                          ⎥\n",
       " 0  0  0  0  0  1  1  0  0⎥\n",
       "                          ⎥\n",
       " 0  0  1  1  1  0  0  0  0⎥\n",
       "                          ⎥\n",
       " 1  0  0  0  1  0  0  0  1⎥\n",
       "                          ⎥\n",
       " 0  0  0  0  0  0  0  0  0⎥\n",
       "                          ⎥\n",
       " 0  0  0  0  0  0  0  1  0⎥\n",
       "                          ⎥\n",
       " 0  0  0  0  0  0  0  0  0⎦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_matrix(result.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acknowledged across alike all am an april are as bright call cold comes day faced families firing happy he in invisible is ishmael it later man many me screaming sky the truth universally was years'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{array}{cccccccccccccccccccc}0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 0\\\\0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\\\0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\end{array}\\right]$$"
      ],
      "text/plain": [
       "⎡0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0⎤\n",
       "⎢                                                          ⎥\n",
       "⎢1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0⎥\n",
       "⎢                                                          ⎥\n",
       "⎢0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  1  0  0  0⎥\n",
       "⎢                                                          ⎥\n",
       "⎢0  0  0  0  0  0  0  1  0  1  0  0  0  1  0  0  0  0  0  1⎥\n",
       "⎢                                                          ⎥\n",
       "⎢0  1  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  0⎥\n",
       "⎢                                                          ⎥\n",
       "⎢0  0  1  1  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0⎥\n",
       "⎢                                                          ⎥\n",
       "⎣0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0⎦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer(\n",
    "    min_df=1, stop_words='english')\n",
    "\n",
    "display_matrix(count_vectorizer.fit_transform(corpus).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acknowledged alike april bright cold comes day faced families firing happy invisible ishmael later man screaming sky truth universally years'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{array}{cccccccccccccccccccc}0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 0\\\\0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\\\0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 2 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 2\\end{array}\\right]$$"
      ],
      "text/plain": [
       "⎡0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0⎤\n",
       "⎢                                                          ⎥\n",
       "⎢1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0⎥\n",
       "⎢                                                          ⎥\n",
       "⎢0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  1  0  0  0⎥\n",
       "⎢                                                          ⎥\n",
       "⎢0  0  0  0  0  0  0  1  0  1  0  0  0  1  0  0  0  0  0  1⎥\n",
       "⎢                                                          ⎥\n",
       "⎢0  1  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  0⎥\n",
       "⎢                                                          ⎥\n",
       "⎢0  0  1  1  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0⎥\n",
       "⎢                                                          ⎥\n",
       "⎢0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0⎥\n",
       "⎢                                                          ⎥\n",
       "⎣0  0  0  0  2  0  1  0  0  0  0  0  0  0  0  0  0  0  0  2⎦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "repetitive_doc = 'On a cold, cold day, years and years ago'\n",
    "\n",
    "counts = count_vectorizer.transform(corpus + [repetitive_doc])\n",
    "\n",
    "display_matrix(counts.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfIdfTransformer\n",
    "\n",
    "\n",
    "Take a matrix of counts, like the one above, and transform it into a matrix where the values for each document are adjusted by the frequency of the term across the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{array}{cccccccccccccccccccc}0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.707106781186547 & 0.0 & 0.0 & 0.707106781186547 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.666666666666667 & 0.0 & 0.333333333333333 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.666666666666667\\end{array}\\right]$$"
      ],
      "text/plain": [
       "⎡0.0  0.0  0.0  0.0         0.0         0.0         0.0         0.0  0.0  0.0 \n",
       "⎢                                                                             \n",
       "⎣0.0  0.0  0.0  0.0  0.666666666666667  0.0  0.333333333333333  0.0  0.0  0.0 \n",
       "\n",
       " 0.0  0.707106781186547  0.0  0.0  0.707106781186547  0.0  0.0  0.0  0.0      \n",
       "                                                                              \n",
       " 0.0         0.0         0.0  0.0         0.0         0.0  0.0  0.0  0.0  0.66\n",
       "\n",
       "   0.0       ⎤\n",
       "             ⎥\n",
       "6666666666667⎦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf_transformer = feature_extraction.text.TfidfTransformer()\n",
    "\n",
    "display_matrix(tfidf_transformer.fit_transform(counts).todense()[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DictVectorizer\n",
    "\n",
    "Turn a list of feature=>value pairs into a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.DictVectorizer(dtype=np.bool, sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_data = [\n",
    "    {'browser': 'Chrome', 'os': 'Mac'},\n",
    "    {'browser': 'Firefox', 'os': 'Windows'},\n",
    "    {'browser': 'Safari', 'os': 'iOS'},\n",
    "    {'browser': 'Firefox', 'os': 'Linux'},\n",
    "    {'browser': 'Chrome', 'os': 'Windows'},\n",
    "    {'browser': 'Chrome', 'os': 'Mac'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'bool'>, separator='=', sort=True, sparse=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False,  True, False, False],\n",
       "       [False,  True, False, False, False,  True, False],\n",
       "       [False, False,  True, False, False, False,  True],\n",
       "       [False,  True, False,  True, False, False, False],\n",
       "       [ True, False, False, False, False,  True, False],\n",
       "       [ True, False, False, False,  True, False, False]], dtype=bool)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = vectorizer.transform(user_data)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['browser=Chrome',\n",
       " 'browser=Firefox',\n",
       " 'browser=Safari',\n",
       " 'os=Linux',\n",
       " 'os=Mac',\n",
       " 'os=Windows',\n",
       " 'os=iOS']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_dict(vectorizer, d):\n",
    "    return vectorizer.transform([d])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False,  True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encountered_values = {'browser': 'Chrome', 'os': 'Mac'}\n",
    "\n",
    "enc_vec = vectorize_dict(vectorizer, encountered_values)\n",
    "\n",
    "enc_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_vectorized_dict(vectorizer, v):\n",
    "    return np.array(vectorizer.get_feature_names())[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['browser=Chrome', 'os=Mac'],\n",
       "      dtype='<U15')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_vectorized_dict(vectorizer, enc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unencountered_values = {'browser': 'Chrome', 'os': 'Android'}\n",
    "\n",
    "unenc_vec = vectorize_dict(vectorizer, unencountered_values)\n",
    "\n",
    "unenc_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['browser=Chrome'],\n",
       "      dtype='<U15')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_vectorized_dict(vectorizer, unenc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'bool'>, separator='=', sort=True, sparse=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(user_data + [unencountered_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 8 but corresponding boolean dimension is 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8300d4584275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecode_vectorized_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munenc_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-23446a521c0c>\u001b[0m in \u001b[0;36mdecode_vectorized_dict\u001b[0;34m(vectorizer, v)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_vectorized_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 8 but corresponding boolean dimension is 7"
     ]
    }
   ],
   "source": [
    "decode_vectorized_dict(vectorizer, unenc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer.inverse_transform(unenc_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeatureHasher\n",
    "\n",
    "Transform a list of feature=>value pairs into a matrix, but without needing to know the range of possible values, and with a risk of hash collision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hasher = feature_extraction.FeatureHasher(n_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "people = [\n",
    "    {'name': 'Alice', 'hobby': 'weiqi', 'age': 32},\n",
    "    {'name': 'Bob', 'state': 'PA', 'age': 27},\n",
    "    {'name': 'Carol', 'hobby': 'chess', 'job': 'Engineer'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = hasher.transform(people)\n",
    "\n",
    "display_matrix(r.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_matrix(hasher.transform([{'name': 'Dan', 'age': 54, 'shoe_size': 10}]).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization scaling\n",
    "\n",
    "Scale an array so that its mean is 0 and its variance is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ages = np.array([21, 78, 36, 61, 56, 30, 64, 25, 60, 17])\n",
    "\n",
    "ages.mean(), ages.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ages_scaled = preprocessing.scale(ages)\n",
    "\n",
    "ages_scaled.mean(), ages_scaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.isclose(ages_scaled.mean(), 0), np.isclose(ages_scaled.var(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-max scaling\n",
    "\n",
    "Scale an array to a given range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ages.min(), ages.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 10))\n",
    "\n",
    "r = min_max_scaler.fit_transform(ages)\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r.min(), r.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarization\n",
    "\n",
    "Binarize an array such that values under `threshold` are false and above `threshold` are true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retirement_binarizer = preprocessing.Binarizer(threshold=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_matrix(retirement_binarizer.fit_transform(ages.reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding\n",
    "\n",
    "Encode categorical values such that each unique value is a boolean in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot_encoder = preprocessing.OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies_genres = [\n",
    "    ['Action', 'Horror', 'Sci-Fi'],\n",
    "    ['Action', 'Drama', 'Romance'],\n",
    "    ['Comedy', 'Drama', 'Sci-Fi'],\n",
    "]\n",
    "\n",
    "try:\n",
    "    one_hot_encoder.fit(movies_genres)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_genres = list(set(itertools.chain.from_iterable(movies_genres)))\n",
    "\n",
    "all_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies_genres_ints = [\n",
    "    [all_genres.index(genre) for genre in movie]\n",
    "    for movie in movies_genres\n",
    "]\n",
    "\n",
    "movies_genres_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_hot_encoder.fit_transform(movies_genres_ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelEncoder\n",
    "\n",
    "Encode labels (ie categories) such that there each label is represented by the same unique integer in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(all_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array([label_encoder.transform(movie) for movie in movies_genres])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelBinarizer\n",
    "\n",
    "Binarize labels such that a matrix is returned in which each row is one-hot encoded label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_binarizer = preprocessing.LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_binarizer.fit(all_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for movie in movies_genres:\n",
    "    print(movie)\n",
    "    print(label_binarizer.transform(movie))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLabelBinarizer\n",
    "\n",
    "Binarize multiple labels like we did with the one-hot encoder above but without all the struggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_label_binarizer = preprocessing.MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "multi_label_binarizer.fit_transform(movies_genres)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
